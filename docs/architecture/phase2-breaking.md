# Phase 2: Breaking Scenarios

## ğŸ¯ Objective

Intentionally break the Phase 1 POC by scaling it beyond its design limits. This teaches you what happens when production systems face real-world challenges without proper engineering.

## ğŸ’¥ Breaking Tests

### Test 1: Large Single File (10,000+ lines)

**Scenario:** Process a massive Python file with 10,000+ lines

**What to Expect:**
- â±ï¸ **Timeout Risk**: Lambda 15-minute limit
- ğŸ’° **High Cost**: Single file could cost â‚¹100-200
- ğŸŒ **Slow Processing**: 5-10 minutes per file
- ğŸ§  **Context Window Issues**: Approaching Claude's token limits

**How to Break:**
```python
# Create a large test file
python tests/test_data/generators/create_large_file.py --lines 10000

# Try to process it
python src/phase1_poc/lambda_function.py --file tests/test_data/large_repo/large_file.py
```

**Expected Failure:**
```
Error: Request timeout after 900 seconds
Cost so far: â‚¹180
Tokens used: ~180,000
```

**Why It Breaks:**
- No chunking strategy
- Entire file sent in one API call
- Single-threaded processing
- No progress tracking

---

### Test 2: Large Repository (50,000 lines, 100+ files)

**Scenario:** Process an entire repository with 100 files totaling 50,000 lines

**What to Expect:**
- ğŸ’¸ **Cost Explosion**: â‚¹4,000+ for single run
- ğŸ• **Extremely Slow**: 2-3 hours total
- âš ï¸ **Rate Limits**: 429 errors from Claude API
- ğŸ’¥ **Lambda Timeout**: Can't process all files in one invocation

**How to Break:**
```python
# Clone a real repository
git clone https://github.com/psf/requests.git tests/test_data/large_repo/requests

# Try to process it (IT WILL FAIL)
python tests/integration/test_large_repo.py
```

**Expected Failures:**
```
File 1/100: âœ“ Success (â‚¹40, 30s)
File 2/100: âœ“ Success (â‚¹35, 28s)
File 3/100: âœ“ Success (â‚¹42, 32s)
...
File 15/100: âœ— Failed - Rate limit exceeded (429)
...
File 30/100: âœ— Failed - Lambda timeout
Total cost before crash: â‚¹1,200
Files completed: 29/100 (29%)
```

**Why It Breaks:**
- No rate limiting implementation
- No retry logic with exponential backoff
- Sequential processing (one file at a time)
- No caching (re-processing identical files)
- No cost caps or budgets
- No progress persistence (crash = start over)

---

### Test 3: Repeated Processing (Same Repo 10 Times)

**Scenario:** Process the same repository 10 times (simulating development workflow)

**What to Expect:**
- ğŸ’° **Wasted Money**: â‚¹400 Ã— 10 = â‚¹4,000 for identical work
- ğŸ”„ **No Caching**: Every run costs the same
- â±ï¸ **Wasted Time**: 30 minutes Ã— 10 = 5 hours

**How to Break:**
```bash
# Run the same test 10 times
for i in {1..10}; do
    python src/phase1_poc/lambda_function.py --file tests/test_data/small_repo/calculator.py
done
```

**Expected Result:**
```
Run 1: âœ“ â‚¹20 (30s)
Run 2: âœ“ â‚¹20 (30s) <- Same cost! No cache!
Run 3: âœ“ â‚¹20 (30s) <- Same cost! No cache!
...
Run 10: âœ“ â‚¹20 (30s)
Total: â‚¹200 for the same file 10 times
With caching: Should be â‚¹20 (first run) + â‚¹0 (cached) Ã— 9 = â‚¹20
Money wasted: â‚¹180 (90% savings possible)
```

**Why It Breaks:**
- No caching layer
- No file hash checking
- No DynamoDB or Redis cache
- Every identical file costs the same

---

### Test 4: Concurrent Requests (10 Files Simultaneously)

**Scenario:** Try to process 10 files at the same time

**What to Expect:**
- ğŸš« **Rate Limit Errors**: Claude API has request-per-minute limits
- âŒ **Multiple Failures**: 7-8 out of 10 requests fail
- ğŸ”„ **No Retry Logic**: Failed requests are lost

**How to Break:**
```python
# Process 10 files concurrently
python tests/integration/test_concurrent.py --files 10
```

**Expected Result:**
```
Starting 10 concurrent requests...

File 1: âœ“ Success (â‚¹25, 20s)
File 2: âœ“ Success (â‚¹30, 22s)
File 3: âœ— Failed - 429 Rate Limit Exceeded
File 4: âœ“ Success (â‚¹28, 21s)
File 5: âœ— Failed - 429 Rate Limit Exceeded
File 6: âœ— Failed - 429 Rate Limit Exceeded
File 7: âœ— Failed - 429 Rate Limit Exceeded
File 8: âœ“ Success (â‚¹32, 23s)
File 9: âœ— Failed - 429 Rate Limit Exceeded
File 10: âœ— Failed - 429 Rate Limit Exceeded

Success Rate: 40%
Total Cost: â‚¹115 (but 60% of work wasted)
```

**Why It Breaks:**
- No rate limiting implementation
- No request queue
- No exponential backoff
- No retry mechanism
- All requests fire simultaneously

---

### Test 5: Memory Intensive File (Complex AST)

**Scenario:** Process a file with extremely complex nested structures

**What to Expect:**
- ğŸ§  **Memory Overflow**: Lambda OOM error
- ğŸ“ˆ **High Memory Usage**: Exceeds 512MB allocation
- ğŸ’¥ **Crash**: No graceful degradation

**How to Break:**
```python
# Create a deeply nested file
python tests/test_data/generators/create_nested_file.py --depth 100

# Try to process it
python src/phase1_poc/lambda_function.py --file tests/test_data/large_repo/deeply_nested.py
```

**Expected Failure:**
```
Analyzing file...
Building AST...
Error: Lambda ran out of memory
Memory used: 520MB / 512MB
Process killed
```

**Why It Breaks:**
- Fixed 512MB memory allocation
- No memory monitoring
- AST parsing of complex files is memory-intensive
- No streaming or chunking

---

## ğŸ“Š Cost Comparison: POC vs Production

| Scenario | POC (Phase 1) | Production (Phase 3) | Savings |
|----------|---------------|---------------------|---------|
| Single file (1,000 lines) | â‚¹20 | â‚¹8 | 60% |
| Large file (10,000 lines) | â‚¹180 | â‚¹50 | 72% |
| Repository (50,000 lines) | â‚¹4,000 | â‚¹240 | **94%** |
| 10 runs of same repo | â‚¹4,000 | â‚¹400 | 90% |
| **Monthly (100 repos)** | **â‚¹40,000** | **â‚¹6,000** | **85%** |

---

## ğŸ“ What You Learn

After experiencing these failures, you'll understand why production systems need:

### 1. **Chunking Strategies**
   - Break large files into manageable pieces
   - Maintain context between chunks
   - Process chunks in parallel

### 2. **Caching Layers**
   - Hash-based file caching
   - TTL-based cache expiration
   - DynamoDB for persistent cache

### 3. **Rate Limiting**
   - Request queues
   - Exponential backoff
   - Respect API quotas

### 4. **Cost Management**
   - Per-request budgets
   - Cost tracking and alerts
   - Optimization opportunities

### 5. **Error Handling**
   - Retry logic with backoff
   - Graceful degradation
   - Detailed error logging

### 6. **Monitoring**
   - CloudWatch metrics
   - Cost per request
   - Success/failure rates
   - Performance tracking

### 7. **Scalability**
   - Parallel processing (ECS)
   - Auto-scaling
   - Load balancing

---

## ğŸ”§ Next Steps

After breaking the system, you'll rebuild it properly in Phase 3 with:

1. âœ… **Intelligent chunking** (2,000 line chunks with overlap)
2. âœ… **DynamoDB caching** (80% cost reduction)
3. âœ… **Rate limiter** with exponential backoff
4. âœ… **Parallel processing** via ECS Fargate
5. âœ… **CloudWatch monitoring** with custom metrics
6. âœ… **Cost tracking** per request
7. âœ… **Error recovery** with retry logic
8. âœ… **Auto-scaling** based on queue depth

---

## ğŸƒ Running the Breaking Tests

```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Add your ANTHROPIC_API_KEY to .env

# Run breaking tests (WARNING: These will fail and cost money)
python tests/integration/test_breaking_scenarios.py

# Or run specific tests
python tests/integration/test_large_file.py
python tests/integration/test_large_repo.py
python tests/integration/test_concurrent.py
```

**âš ï¸ Warning:** These tests will actually call the Claude API and incur costs. Budget â‚¹500-1,000 for testing all scenarios.

---

## ğŸ“ˆ Metrics to Track

As you run these tests, track:

1. **Cost per scenario**
2. **Success rate** (% of files processed)
3. **Processing time** per file
4. **API errors** (count and types)
5. **Memory usage**
6. **Token consumption**

This data will help you understand the improvements in Phase 3.

---

**Remember:** Breaking systems intentionally in a controlled environment is how you learn what NOT to do in production. Every failure here teaches a valuable lesson about production engineering.
